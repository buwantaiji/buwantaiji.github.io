<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <title>Linear Algebra Autodiff (complex valued)</title>
  <meta name="description" content="">
  <meta name="author" content="Wei Wang">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Linear Algebra Autodiff (complex valued)">
  <meta name="twitter:description" content="">
  
  <meta property="og:type" content="article">
  <meta property="og:title" content="Linear Algebra Autodiff (complex valued)">
  <meta property="og:description" content="">
  
  <link rel="icon" type="image/png" href="/assets/images/favicon.png" />
  <link href="/assets/images/favicon.png" rel="shortcut icon" type="image/png">
  
  <link rel="stylesheet" href="/css/main.css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="canonical" href="http://localhost:4000/2019/10/test/">
  <link rel="alternate" type="application/rss+xml" title="Hao Xie" href="http://localhost:4000/feed.xml">
  
  <meta name="google-site-verification" content="1-1ZlHoRvM0T2FqPbW2S-qLgYXN6rsn52kErlMPd_gw" />
  
</head>


  <body>

    <span class="mobile btn-mobile-menu">
        <i class="fa fa-list btn-mobile-menu__icon"></i>
        <i class="fa fa-angle-up btn-mobile-close__icon hidden"></i>
    </span>
    
    <header class="panel-cover panel-cover--collapsed" style="background-image: url('/assets/images/background-cover.jpg')">
  <div class="panel-main">

    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        <a href="/#blog" title="前往 Hao Xie 的主页" class="blog-button"><img src="/assets/images/avatar.jpg" width="80" alt="Hao Xie logo" class="panel-cover__logo logo" /></a>
        <h1 class="panel-cover__title panel-title"><a href="/#blog" title="link to homepage for Hao Xie" class="blog-button">Hao Xie</a></h1>
        
        <hr class="panel-cover__divider" />
        <p class="panel-cover__description">Ph.D. candidate at IOP, CAS</p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        
        
        
        <div class="navigation-wrapper">
          <div>
            <nav class="cover-navigation cover-navigation--primary">
              <ul class="navigation">
                <li class="navigation__item"><a href="/#blog" title="Visit blog" class="blog-button">Blog</a></li>
                
              </ul>
            </nav>
          </div>
          
          <div><nav class="cover-navigation navigation--social">
  <ul class="navigation">

  

  
  <!-- Github -->
  <li class="navigation__item">
    <a href="https://github.com/buwantaiji" title="@buwantaiji 的 Github" target="_blank">
      <i class='social fa fa-github'></i>
      <span class="label">Github</span>
    </a>
  </li>
  
  
  

  

  <!-- RSS -->
  <li class="navigation__item">
    <a href="/feed.xml" rel="author" title="RSS" target="_blank">
      <i class='social fa fa-rss'></i>
      <span class="label">RSS</span>
    </a>
  </li>

  
  <!-- Email -->
  <li class="navigation__item">
    <a href="mailto:xiehao18@iphy.ac.cn" title="Contact me">
      <i class='social fa fa-envelope'></i>
      <span class="label">Email</span>
    </a>
  </li>
  

  </ul>
</nav>
</div>
        </div>
      </div>
    </div>
    
    
    <div class="panel-cover--overlay cover-disabled"></div>
    
  </div>
</header>


    <div class="content-wrapper">
        <div class="content-wrapper__inner">
            <article class="post-container post-container--single" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <div class="post-meta">
      <time datetime="2019-10-13 00:00:00 +0800" itemprop="datePublished" class="post-meta__date date">2019-10-13</time> &#8226; <span class="post-meta__tags tags"></span>
    </div>
    <h1 class="post-title">Linear Algebra Autodiff (complex valued)</h1>
  </header>

  <section class="post">
    <script type="text/javascript" async="" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>

<p>You can find the Julia implementations in <a href="https://github.com/GiggleLiu/BackwardsLinalg.jl">BackwardsLinalg.jl</a> and <a href="https://github.com/under-Peter/OMEinsum.jl">OMEinsum.jl</a>.</p>

<h2 id="einsum">Einsum</h2>
<hr />

<h3 id="definition-of-einsum">Definition of Einsum</h3>

<p><code class="highlighter-rouge">einsum</code> is defined as</p>

<script type="math/tex; mode=display">% <![CDATA[
\mathbf{V}_1 \times \mathbf{V}_2 =  \begin{vmatrix}
\mathbf{i} & \mathbf{j} & \mathbf{k} \\
\frac{\partial X}{\partial u} &  \frac{\partial Y}{\partial u} & 0 \\
\frac{\partial X}{\partial v} &  \frac{\partial Y}{\partial v} & 0 \\
\end{vmatrix} %]]></script>

<script type="math/tex; mode=display">O_{\vec o} = \sum\limits_{(\vec a \cup \vec b \cup \vec c \ldots) \backslash \vec o }A_{\vec a}B_{\vec b}C_{\vec c} \ldots,</script>

<p>where $\vec a = a_1, a_2\dots$ are labels that appear in tensor $A$, $\vec a\cup \vec b$ means the union of two sets of labels, $\vec a\backslash \vec b$ means setdiff between two sets of labels. The above sumation runs over all indices that does not appear in output tensor $O$.</p>

<h2 id="autodiff">Autodiff</h2>
<hr />

<p>Given $\overline O$, In order to to obtain $\overline B \equiv \partial \mathcal{L}/\partial B$, consider the the diff rule</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\delta \mathcal{L} &= \sum\limits_{\vec o} \overline O_{\vec o} \delta O_{\vec o} \\
&=\sum\limits_{\vec o\cup\vec a \cup \vec b\cup \vec c \ldots} \overline O_{\vec o}A_{\vec a}\delta B_{\vec b}C_{\vec c} \ldots
\end{align} %]]></script>

<p>Here, we have used the (partial) differential equation</p>

<script type="math/tex; mode=display">\delta O_{\vec o} = \sum\limits_{(\vec a \cup \vec b \cup \vec c \ldots) \backslash \vec o }A_{\vec a}\delta B_{\vec b}C_{\vec c} \ldots</script>

<p>Then we define</p>

<script type="math/tex; mode=display">\overline B_{\vec b} = \sum\limits_{(\vec a \cup \vec b \cup \vec c \ldots) \backslash \vec b }A_{\vec a}\overline O_{\vec o}C_{\vec c} \ldots,</script>

<p>We can readily verify</p>

<script type="math/tex; mode=display">\delta \mathcal{L} = \sum\limits_{\vec b} \overline B_{\vec b} \delta B_{\vec b}</script>

<p>This backward rule is exactly an einsum that exchange output tensor $O$ and input tensor $B$.</p>

<p>In conclusion, the <code class="highlighter-rouge">index magic</code> of exchanging indices as backward rule holds for einsum.</p>

<p>Thank <a href="https://github.com/under-Peter">Andreas Peter</a> for helpful discussion.</p>

<h2 id="symmetric-eigenvalue-decomposition-ed">Symmetric Eigenvalue Decomposition (ED)</h2>
<hr />
<p><em>references</em>:</p>
<ol>
  <li><a href="https://arxiv.org/abs/1710.08717">https://arxiv.org/abs/1710.08717</a></li>
</ol>

<script type="math/tex; mode=display">A = UEU^\dagger</script>

<p>We have</p>

<script type="math/tex; mode=display">\overline{A} = U\left[\overline{E} + \frac{1}{2}\left(\overline{U}^\dagger U \circ F + h.c.\right)\right]U^\dagger</script>

<p>Where $F_{ij}=(E_j- E_i)^{-1}$.</p>

<p>If $E$ is continuous, we define the density $\rho(E) = \sum\limits_k \delta(E-E_k)=-\frac{1}{\pi}\int_k \Im[G^r(E, k)] $ (check sign!). Where $G^r(E, k) = \frac{1}{E-E_k+i\delta}$.</p>

<p>We have
<script type="math/tex">\overline{A} = U\left[\overline{E} + \frac{1}{2}\left(\overline{U}^\dagger U \circ \Re [G(E_i, E_j)] + h.c.\right)\right]U^\dagger</script></p>

<h2 id="singular-value-decomposition-svd">Singular Value Decomposition (SVD)</h2>
<hr />

<p><em>references</em>:</p>

<ol>
  <li><a href="https://people.maths.ox.ac.uk/gilesm/files/NA-08-01.pdf">https://people.maths.ox.ac.uk/gilesm/files/NA-08-01.pdf</a></li>
  <li><a href="https://j-towns.github.io/papers/svd-derivative.pdf">https://j-towns.github.io/papers/svd-derivative.pdf</a></li>
  <li><a href="https://arxiv.org/abs/1907.13422">https://arxiv.org/abs/1907.13422</a></li>
</ol>

<p>Complex valued SVD is defined as $A = USV^\dagger$. For simplicity, we consider a <strong>full rank square matrix</strong> $A$.
Differentiation gives</p>

<script type="math/tex; mode=display">dA = dUSV^\dagger + U dS V^\dagger + USdV^\dagger</script>

<script type="math/tex; mode=display">U^\dagger dA V = U^\dagger dU S + dS + SdV^\dagger V</script>

<p>Defining matrices $dC=U^\dagger dU$ and $dD = dV^\dagger V$ and $dP = U^\dagger dA V$, then we have</p>

<script type="math/tex; mode=display">\begin{cases}dC^\dagger+dC=0,\\dD^\dagger +dD=0\end{cases}</script>

<p>We have</p>

<script type="math/tex; mode=display">dP = dC S + dS + SdD</script>

<p>where $dCS$ and $SdD$ has zero real part in diagonal elements. So that $dS = \Re[{\rm diag}(dP)]$.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
d\mathcal{L} &= {\rm Tr}\left[\overline{A}^TdA+\overline{A^*}^TdA^*\right]\\
&= {\rm Tr}\left[\overline{A}^TdA+dA^\dagger\overline{A}^*\right] ~~~~~~~\#rule~3
\end{align} %]]></script>

<p>Easy to show $\overline A_s = U^*\overline SV^T$. Notice here, $\overline A$ is the <strong>derivative</strong> rather than <strong>gradient</strong>, they are different by a conjugate, this is why we have transpose rather than conjugate here. see my <a href="https://giggleliu.github.io/2018/02/01/complex_bp.html">complex valued autodiff blog</a> for detail.</p>

<p>Using the relations $dC^\dagger+dC=0$ and $dD^\dagger+dD=0$</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{cases}
dPS + SdP^\dagger &= dC S^2-S^2dC\\
SdP + dP^\dagger S &= S^2dD-dD S^2
\end{cases} %]]></script>

<script type="math/tex; mode=display">\begin{cases}
dC = F\circ(dPS+SdP^\dagger)\\
dD = -F\circ (SdP+dP^\dagger S)
\end{cases}</script>

<p>where $F_{ij} = \frac{1}{s_j^2-s_i^2}$, easy to verify $F^T = -F$. Notice here, the relation between the imaginary diagonal parts  is lost</p>

<script type="math/tex; mode=display">\color{red}{\Im[I\circ dP] = \Im[I\circ(dC+dD)]} ~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~\text{Eq. 1}</script>

<p>This <strong>the missing diagonal imaginary part</strong> is definitely not trivial, but has been ignored for a long time until <a href="https://github.com/tensorflow/tensorflow/issues/13641#issuecomment-526976200">@refraction-ray</a> (Shixin Zhang) mentioned and solved it. Let’s first focus on the off-diagonal contributions from $dU$</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
{\rm Tr}\overline U^TdU &= {\rm Tr} \overline U ^TU dC + \overline U^T (I-UU^\dagger) dAVS^{-1}\\
&= {\rm Tr}\overline U^T U (F\circ(dPS+SdP^\dagger))\\
 &=  {\rm Tr}(dPS+SdP^\dagger)(-F\circ (\overline U^T U))~~~~~~~~~~~~~~\# rule~1,2\\
 &= {\rm Tr}(dPS+SdP^\dagger)J^T
\end{align} %]]></script>

<p>Here, we defined $J=F\circ(U^T\overline U)$.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
d\mathcal L &= {\rm Tr} (dPS+SdP^\dagger)(J+J^\dagger)^T\\
&= {\rm Tr} dPS(J+J^\dagger)^T+h.c.\\
&= {\rm Tr} U^\dagger dA V S(J+J^\dagger)^T+h.c.\\
&= {\rm Tr}\left[ VS(J+J^\dagger)^TU^\dagger\right] dA+h.c.
\end{align} %]]></script>

<p>By comparing with $d\mathcal L = {\rm Tr}\left[\overline{A}^TdA+h.c. \right]$, we have</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\bar A_U^{(\rm real)} &=  \left[VS(J+J^\dagger)^TU^\dagger\right]^T\\
&=U^*(J+J^\dagger)SV^T
\end{align} %]]></script>

<h4 id="update-the-missing-diagonal-imaginary-part">Update: The missing diagonal imaginary part</h4>
<hr />

<p>Now let’s inspect the diagonal imaginary parts of $dC$ and $dD$ in Eq. 1. At a first glance, it is not sufficient to derive $dC$ and $dD$ from $dP$, but consider there is still an information not used, <strong>the loss must be gauge invariant</strong>, which means</p>

<script type="math/tex; mode=display">\mathcal{L}(U\Lambda, S, V\Lambda)</script>

<p>Should be independent of the choice of gauge $\Lambda$, which is defined as ${\rm diag}(e^i\phi, …)$</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
d\mathcal{L} &={\rm Tr}[ \overline{U\Lambda}^T d(U\Lambda) +\overline  SdS+\overline{V\Lambda}^Td(V\Lambda)] + h.c.\\
&={\rm Tr}[ \overline {U\Lambda}^T (dU\Lambda+Ud\Lambda) +\overline{S}dS+  \overline{V\Lambda}^T(Vd\Lambda +dV\Lambda)] + h.c.\\
&= {\rm Tr}[(\overline{U\Lambda}^TU+\overline{V\Lambda}^TV )d\Lambda ] + \ldots + h.c.
\end{align} %]]></script>

<p>Gauge invariance refers to</p>

<script type="math/tex; mode=display">\overline{\Lambda} =  I\circ(\overline{U\Lambda}^TU+\overline{V\Lambda}^TV) = 0</script>

<p>For any $\Lambda$, where $I$ refers to the diagonal mask matrix. It is of cause valid when $\Lambda\rightarrow1$, $I\circ(\overline{U}^TU+\overline V^TV) = 0$.</p>

<p>Consider the contribution from the <strong>diagonal imaginary part</strong>, we have</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
&{\rm Tr} [\overline U^T U (I \circ \Im [dC])+\overline V^T V (I \circ \Im [dD^\dagger])] + h.c.\\
&={\rm Tr} [ I \circ (\overline U^T U)\Im [dC]-I\circ (\overline V^T V) \Im [dD]] +h.c. ~~~~~~~~~~~~~~\#  rule 1\\
&={\rm Tr} [ I \circ (\overline U^T U)(\Im [dC]+ \Im [dD])] \\
&={\rm Tr}[I\circ (\overline U^T U) \Im[dP]S^{-1}]  \\
&={\rm Tr}[S^{-1}\Lambda_J U^{\dagger}dA V]\\
\end{align} %]]></script>

<p>where $\Lambda_J  = \Im[I\circ(\overline U^TU)]= \frac 1 2I\circ(\overline U^TU)-h.c.$, with $I$ the mask for diagonal part. Since only the real part contribute to $\delta \mathcal{L}$ (the imaginary part will be canceled by the Hermitian conjugate counterpart), we can safely move $\Im$ from right to left.</p>

<script type="math/tex; mode=display">\begin{align}
\color{red}{\bar A_{U+V}^{(\rm imag)} = U^*\Lambda_J S^{-1}V^T}
\end{align}</script>

<p><strong>Thanks  <a href="https://github.com/refraction-ray">@refraction-ray</a> (Shixin Zhang) for sharing his idea in the first time. This is the <a href="https://github.com/tensorflow/tensorflow/issues/13641#issuecomment-526976200">issue for discussion</a>. His arXiv preprint is coming out soon.</strong></p>

<p>When $U$ is <strong>not full rank</strong>, this formula should take an extra term (Ref. 2)</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\bar A_U^{(\rm real)} &=U^*(J+J^\dagger)SV^T + (VS^{-1}\overline U^T(I-UU^\dagger))^T
\end{align} %]]></script>

<p>Similarly, for $V​$ we have</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\overline A_V^{(\rm real)} &=U^*S(K+K^\dagger)V^T + (U S^{-1} \overline V^T (I - VV^\dagger))^*,
\end{align} %]]></script>

<p>where $K=F\circ(V^T\overline V)​$.</p>

<p>To wrap up</p>

<script type="math/tex; mode=display">\overline A = \overline A_U^{\rm (real)} + \overline A_S + \overline A_V^{\rm (real)} +  \overline A_{U+V}^{\rm (imag)}</script>

<p>This result can be directly used in <strong>autograd</strong>.</p>

<p>For the <strong>gradient</strong> used in training, one should change the convention</p>

<script type="math/tex; mode=display">\mathcal{\overline A} = \overline A^*,\\ \mathcal{\overline U} = \overline U^*,\\ \mathcal{\overline V}= \overline V^*.</script>

<p>This convention is used in <strong>tensorflow</strong>, <strong>Zygote.jl</strong>. Which is</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\mathcal{\overline A} =& U(\mathcal{J}+\mathcal{J}^\dagger)SV^\dagger + (I-UU^\dagger)\mathcal{\overline U}S^{-1}V^\dagger\\
&+ U\overline SV^\dagger\\
&+US(\mathcal{K}+\mathcal{K}^\dagger)V^\dagger + U S^{-1} \mathcal{\overline V}^\dagger (I - VV^\dagger)\\
&\color{red}{+\frac 1 2 U (I\circ(U^\dagger\overline U)-h.c.)S^{-1}V^\dagger}
\end{align} %]]></script>

<p>where $J=F\circ(U^\dagger\mathcal{\overline U})$ and $K=F\circ(V^\dagger \mathcal{\overline V})$.</p>

<h3 id="rules">Rules</h3>

<p>rule 1. ${\rm Tr} \left[A(C\circ B\right)] = \sum A^T\circ C\circ B = {\rm Tr} ((C\circ A^T)^TB)={\rm Tr}(C^T\circ A)B$</p>

<p>rule2. $(C\circ A)^T = C^T \circ A^T$</p>

<p>rule3. When $\mathcal L$ is real, <script type="math/tex">\frac{\partial \mathcal{L}}{\partial x^*} =  \left(\frac{\partial \mathcal{L}}{\partial x}\right)^*</script></p>

<h3 id="how-to-test-svd">How to Test SVD</h3>

<p>e.g. To test the adjoint contribution from $U$, we can construct a gauge insensitive  test function</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># H is a random Hermitian Matrix</span>
<span class="k">function</span><span class="nf"> loss</span><span class="x">(</span><span class="n">A</span><span class="x">)</span>
    <span class="n">U</span><span class="x">,</span> <span class="n">S</span><span class="x">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">svd</span><span class="x">(</span><span class="n">A</span><span class="x">)</span>
    <span class="n">psi</span> <span class="o">=</span> <span class="n">U</span><span class="x">[</span><span class="o">:</span><span class="x">,</span><span class="mi">1</span><span class="x">]</span>
    <span class="n">psi</span><span class="err">'</span><span class="o">*</span><span class="n">H</span><span class="o">*</span><span class="n">psi</span>
<span class="k">end</span>

<span class="k">function</span><span class="nf"> gradient</span><span class="x">(</span><span class="n">A</span><span class="x">)</span>
    <span class="n">U</span><span class="x">,</span> <span class="n">S</span><span class="x">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">svd</span><span class="x">(</span><span class="n">A</span><span class="x">)</span>
    <span class="n">dU</span> <span class="o">=</span> <span class="n">zero</span><span class="x">(</span><span class="n">U</span><span class="x">)</span>
    <span class="n">dS</span> <span class="o">=</span> <span class="n">zero</span><span class="x">(</span><span class="n">S</span><span class="x">)</span>
    <span class="n">dV</span> <span class="o">=</span> <span class="n">zero</span><span class="x">(</span><span class="n">V</span><span class="x">)</span>
    <span class="n">dU</span><span class="x">[</span><span class="o">:</span><span class="x">,</span><span class="mi">1</span><span class="x">]</span> <span class="o">=</span> <span class="n">U</span><span class="x">[</span><span class="o">:</span><span class="x">,</span><span class="mi">1</span><span class="x">]</span><span class="err">'</span><span class="o">*</span><span class="n">H</span>
    <span class="n">dA</span> <span class="o">=</span> <span class="n">svd_back</span><span class="x">(</span><span class="n">U</span><span class="x">,</span> <span class="n">S</span><span class="x">,</span> <span class="n">V</span><span class="x">,</span> <span class="n">dU</span><span class="x">,</span> <span class="n">dS</span><span class="x">,</span> <span class="n">dV</span><span class="x">)</span>
    <span class="n">dA</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="qr-decomposition">QR decomposition</h2>
<hr />

<script type="math/tex; mode=display">A = QR</script>

<p>with $Q^\dagger Q = \mathbb{I}$, so that $dQ^\dagger Q+Q^\dagger dQ=0$. $R$ is a complex upper triangular matrix, with diagonal part real.
<script type="math/tex">dA = dQR+QdR</script></p>

<script type="math/tex; mode=display">dQ = dAR^{-1}-QdRR^{-1}</script>

<script type="math/tex; mode=display">\begin{cases}
Q^\dagger dQ = dC - dRR^{-1}\\
dQ^\dagger Q =dC^\dagger - R^{-\dagger}dR^\dagger
\end{cases}</script>

<p>where $dC=Q^\dagger dAR^{-1}$.</p>

<p>Then</p>

<script type="math/tex; mode=display">dC+dC^\dagger = dRR^{-1} +(dRR^{-1})^\dagger</script>

<p>Notice $dR$ is upper triangular and its diag is lower triangular, this restriction gives</p>

<script type="math/tex; mode=display">U\circ(dC+dC^\dagger) = dRR^{-1}</script>

<p>where $U$ is a mask operator that its element value is $1$ for upper triangular part, $0.5$ for diagonal part and $0$ for lower triangular part. One should also notice here both $R$ and $dR$ has real diagonal parts, as well as the product $dRR^{-1}$.</p>

<p>Now let’s wrap up using the Zygote convension of gradient</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
d\mathcal L &= {\rm Tr}\left[\overline{\mathcal{Q}}^\dagger dQ+\overline{\mathcal{R}}^\dagger dR +h.c. \right]\\
&={\rm Tr}\left[\overline{\mathcal{Q}}^\dagger dA R^{-1}-\overline{\mathcal{Q}}^\dagger QdR
R^{-1}+\overline{\mathcal{R}}^\dagger dR +h.c. \right]\\
&={\rm Tr}\left[ R^{-1}\overline{\mathcal{Q}}^\dagger dA+ R^{-1}(-\overline{\mathcal{Q}}^\dagger Q +R\overline{\mathcal{R}}^\dagger) dR +h.c. \right]\\
&={\rm Tr}\left[ R^{-1}\overline{\mathcal{Q}}^\dagger dA+ R^{-1}M dR +h.c. \right]
\end{align} %]]></script>

<p>here, $M=R\overline{\mathcal{R}}^\dagger-\overline{\mathcal{Q}}^\dagger Q$. Plug in $dR$ we have</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
d\mathcal{L}&={\rm Tr}\left[ R^{-1}\overline{\mathcal{Q}}^\dagger dA + M \left[U\circ(dC+dC^\dagger)\right] +h.c. \right]\\
&={\rm Tr}\left[ R^{-1}\overline{\mathcal{Q}}^\dagger dA + (M\circ L)(dC+dC^\dagger) +h.c. \right]  \;\;\# rule\; 1\\
&={\rm Tr}\left[ (R^{-1}\overline{\mathcal{Q}}^\dagger dA+h.c.) + (M\circ L)(dC + dC^\dagger)+ (M\circ L)^\dagger (dC + dC^\dagger)\right]\\
&={\rm Tr}\left[ R^{-1}\overline{\mathcal{Q}}^\dagger dA + (M\circ L+h.c.)dC + h.c.\right]\\
&={\rm Tr}\left[ R^{-1}\overline{\mathcal{Q}}^\dagger dA + (M\circ L+h.c.)Q^\dagger dAR^{-1}\right]+h.c.\\
\end{align} %]]></script>

<p>where $L =U^\dagger = 1-U$ is the mask of lower triangular part of a matrix.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\mathcal{\overline A}^\dagger &= R^{-1}\left[\overline{\mathcal{Q}}^\dagger + (M\circ L+h.c.)Q^\dagger\right]\\
\mathcal{\overline A} &= \left[\overline{\mathcal{Q}} + Q(M\circ L+h.c.)\right]R^{-\dagger}\\
&=\left[\overline{\mathcal{Q}} + Q \texttt{copyltu}(M)\right]R^{-\dagger}
\end{align} %]]></script>

<p>Here, the $\texttt{copyltu}​$ takes conjugate when copying elements to upper triangular part.</p>

  </section>
</article>

            <section class="footer">
    <footer>
    	<span class="footer__copyright">本站点采用<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享 署名-非商业性使用-相同方式共享 4.0 国际 许可协议</a></span>
        <span class="footer__copyright">由 <a href="https://jekyllrb.com">Jekyll</a> 于 2019-10-13 生成，感谢 <a href="https://www.digitalocean.com/?refcode=30ed2d146762">Digital Ocean</a> 为本站提供稳定的 VPS 服务</span>
        <span class="footer__copyright">本站由 <a href="http://onev.cat">@onevcat</a> 创建，采用 <a href="https://github.com/onevcat/vno-jekyll">Vno - Jekyll</a> 作为主题，您可以在 GitHub 找到<a href="https://github.com/onevcat/OneV-s-Den">本站源码</a> - &copy; 2019</span>
    </footer>
</section>

        </div>
    </div>
    
    <script type="text/javascript" src="//code.jquery.com/jquery-1.11.3.min.js"></script>

<script type="text/javascript" src="/js/main.js"></script>



    
  </body>

</html>
